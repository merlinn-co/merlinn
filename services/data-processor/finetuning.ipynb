{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from loader import get_documents\n",
    "\n",
    "\n",
    "organization_id = \"65d7cfecff1b3ee6872373d9\"\n",
    "data_sources = [\"Notion\", \"Slack\", \"Github\"]\n",
    "documents, _ = asyncio.run(get_documents(organization_id, data_sources))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_slack_documents(documents):\n",
    "    new_documents = []\n",
    "    for document in documents:\n",
    "        if document.text.startswith(\"<@\") and \"has joined the channel\" in document.text:\n",
    "            continue\n",
    "        if document.text.startswith(\"<@\") and \"has left the channel\" in document.text:\n",
    "            continue\n",
    "        if document.text.startswith(\"<@\") and \"changed their status\" in document.text:\n",
    "            continue\n",
    "        if len(document.text.split(\" \")) <= 10:\n",
    "            continue\n",
    "        new_documents.append(document)\n",
    "    return new_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_documents = filter_slack_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import express, { Request, Response } from \"express\";\\nimport { vendorModel } from \"../db/models/vendor\";\\nimport { checkJWT, getDBUser, checkBetaAccess } from \"../middlewares/auth\";\\nimport { catchAsync } from \"../utils/errors\";\\n\\nconst router = express.Router();\\nrouter.use(checkJWT);\\nrouter.use(getDBUser);\\n// TODO: remove once we finish with beta testing ang do public!\\nrouter.use(checkBetaAccess);\\n\\nrouter.get(\\n  \"/\",\\n  catchAsync(async (req: Request, res: Response) => {\\n    const vendors = await vendorModel.get({});\\n\\n    return res.status(200).json(vendors);\\n  }),\\n);\\n\\nexport { router };\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random_index = random.randint(0, len(new_documents) - 1)\n",
    "\n",
    "new_documents[random_index].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import express, { Request, Response } from \"express\";\\nimport { vendorModel } from \"../db/models/vendor\";\\nimport { checkJWT, getDBUser, checkBetaAccess } from \"../middlewares/auth\";\\nimport { catchAsync } from \"../utils/errors\";\\n\\nconst router = express.Router();\\nrouter.use(checkJWT);\\nrouter.use(getDBUser);\\n// TODO: remove once we finish with beta testing ang do public!\\nrouter.use(checkBetaAccess);\\n\\nrouter.get(\\n  \"/\",\\n  catchAsync(async (req: Request, res: Response) => {\\n    const vendors = await vendorModel.get({});\\n\\n    return res.status(200).json(vendors);\\n  }),\\n);\\n\\nexport { router };\\n'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_documents[random_index].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_path': 'src/routers/vendors.ts',\n",
       " 'file_name': 'vendors.ts',\n",
       " 'url': 'https://github.com/merlinn-co/api/blob/a171919badc9d61a0cc17198778bf930d9224026/src/routers/vendors.ts',\n",
       " 'repo_path': 'merlinn-co/api',\n",
       " 'commit_sha': 'a171919badc9d61a0cc17198778bf930d9224026',\n",
       " 'branch': 'main',\n",
       " 'source': 'Github'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_documents[random_index].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llama_dataset.generator import RagDatasetGenerator\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "api_key = \"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\"\n",
    "llm_35 = OpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.3, api_key=api_key)\n",
    "\n",
    "dataset_generator = RagDatasetGenerator.from_documents(\n",
    "    documents=new_documents[:10],\n",
    "    llm=llm_35,\n",
    "    num_questions_per_chunk=10, # set the number of questions per nodes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_dataset = dataset_generator.generate_dataset_from_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** Query ******************************\n",
      "What specific error was found in the log context data related to user session information?\n",
      "****************************** Answer ******************************\n",
      "The specific error found in the log context data related to user session information is \"Failed to fetch.\" This error is mentioned in the log entry and is consistent with the issue of users not being able to pay, as indicated in the log analysis.\n",
      "****************************** Context ******************************\n",
      "**Log Analysis:**\n",
      "   - Multiple logs indicate the message \"User could not pay\" with a severity level of 6.\n",
      "   - The logs contain user session information and indicate \"Failed to fetch\" in the log context data error.\n",
      "   - Additional logs show network requests with \"Failed to fetch\" status during the checkout process.\n",
      "\n",
      "3. **Code Changes:**\n",
      "   - The latest code change in the `demo-app` repository involves removing the increment of the index in the `calculatePrice` function.\n",
      "\n",
      "4. **Next Steps:**\n",
      "   - The code change in `payment.py` might be related to the issue of users not being able to pay.\n",
      "   - Further investigation is needed to determine if this code change is causing the payment failure.\n",
      "\n",
      "I will continue the investigation to gather more information and identify the root cause of the issue.\n",
      "\n",
      "*Sources :scroll:*\n",
      " â€¢  <https://merlinn.app.eu2.coralogix.com/#/query-new/logs?query=source%20logs%20%7C%20lucene%20'Failed%20to%20fetch'%20%7C%20limit%2020&amp;time=from:2024-02-09T11:54:28.335Z,to:2024-02-09T12:54:28.335Z&amp;page=0&amp;querySyntax=dataprime&amp;permalink=true|Coralogix Logs Link>\n",
      "\n",
      "<@U06FURXUM9T> Thanks! Can you suggest a fix to this problem?\n",
      "\n",
      "Based on the information gathered, it seems that the issue of users not being able to pay is related to the \"Failed to fetch\" error in the network requests during the checkout process. Additionally, the latest code change in the `payment.py` file involves removing the increment of the index in the `calculatePrice` function.\n",
      "\n",
      "To address this issue, I recommend the following steps:\n",
      "\n",
      "1. **Review the Code Change:**\n",
      "   - Investigate the code change in the `payment.py` file to understand the impact of removing the increment of the index in the `calculatePrice` function. Determine if this change is causing the payment failure.\n",
      "\n",
      "2. **Check Network Requests:**\n",
      "   - Review the network requests for the checkout process and identify the root cause of the \"Failed to fetch\" error. This may involve debugging the network requests and ensuring that the API endpoint for the checkout process is functioning correctly.\n",
      "\n",
      "3. **Testing and Rollback:**\n",
      "   - If the code change is identified as the cause of the payment failure, consider rolling back the change and testing the payment functionality to verify that the issue is resolved.\n",
      "\n",
      "4. **Monitoring and Alerting:**\n",
      "   - Implement monitoring and alerting for network request failures and payment-related errors to proactively detect and address similar issues in the future.\n",
      "\n",
      "I will continue the investigation to gather more information and provide additional insights. If you need further assistance or have any specific questions, feel free to ask!\n",
      "\n",
      "<@U06FURXUM9T> Thanks! Can you look at this image?\n",
      "\n",
      "Certainly! The image you've provided appears to be a screenshot of a logging dashboard, possibly from a service like Coralogix, which is used for monitoring and analyzing log data in real-time. The screenshot shows a graph and a detailed log entry.\n",
      "\n",
      "Here are some observations from the image:\n",
      "\n",
      "1. **Graph Analysis:**\n",
      "   - The graph at the top of the dashboard displays a time series with spikes that likely represent the occurrence of critical log events over time. The color purple is used to denote these events, and the graph indicates that these events are happening periodically.\n",
      "\n",
      "2. **Log Entry Details:**\n",
      "   - The log entry shown is timestamped \"09/02/2024 14:26:57.268 pm\" and contains various pieces of information, including:\n",
      "     - A unique span ID and trace ID, which are used for tracing requests in distributed systems.\n",
      "     - The application name (`demo-app`) and version (`1.0`).\n",
      "     - An error message: \"Failed to fetch,\" which is consistent with the issue previously discussed.\n",
      "     - User-related information such as email (`<mailto:test@test.com|test@test.com>`), operating system (`MacOS`), and browser details (`Chrome`).\n",
      "     - Geolocation data, including IP address, continent (`Asia`), and country (`Israel`).\n",
      "     - The severity level of the log is marked as 6, which might indicate a high level of importance or criticality.\n",
      "     - The URL of the page where the error occurred\n"
     ]
    }
   ],
   "source": [
    "# random_index = random.randint(0, 10 - 1)\n",
    "random_index = 11\n",
    "print(\"****************************** Query ******************************\")\n",
    "print(rag_dataset.examples[random_index].query)\n",
    "print(\"****************************** Answer ******************************\")\n",
    "print(rag_dataset.examples[random_index].reference_answer)\n",
    "print(\"****************************** Context ******************************\")\n",
    "print(rag_dataset.examples[random_index].reference_contexts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-processor-cjTeTu81-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
